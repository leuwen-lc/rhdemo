# R√©cup√©ration apr√®s perte de donn√©es Keycloak

## üö® Probl√®me rencontr√©

Apr√®s un red√©marrage de machine, les donn√©es du realm `RHDemo` dans Keycloak ont √©t√© perdues.

### Cause racine

Le cluster KinD utilisait des volumes `hostPath` **√† l'int√©rieur du conteneur Docker** du node KinD :
- Volume : `/var/local-path-provisioner/pvc-xxx` (dans le conteneur rhdemo-control-plane)
- **Probl√®me** : Lors du red√©marrage machine, le node Docker est recr√©√© avec un nouveau filesystem
- Les PersistentVolumes ont une politique `RECLAIM POLICY: Delete`
- R√©sultat : Toutes les donn√©es sont perdues (base Keycloak r√©initialis√©e avec uniquement le realm `master`)

### √âv√©nement Kubernetes observ√©

```
39m  Normal  SandboxChanged  pod/postgresql-keycloak-0  Pod sandbox changed, it will be killed and re-created.
```

---

## ‚úÖ Solution imm√©diate : R√©initialiser Keycloak

### √âtape 1 : Restaurer la configuration Keycloak

Utiliser le script d'initialisation automatique :

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./init-keycloak-stagingkub.sh
```

Ce script va :
1. ‚úÖ D√©chiffrer automatiquement les secrets de stagingkub avec SOPS
2. ‚úÖ Cr√©er un port-forward vers Keycloak
3. ‚úÖ Recr√©er le realm `RHDemo`
4. ‚úÖ Recr√©er le client OAuth2 avec le bon secret
5. ‚úÖ Recr√©er les 3 utilisateurs de test avec leurs r√¥les

### √âtape 2 : V√©rifier la restauration

```bash
# V√©rifier les realms dans la base
kubectl exec -n rhdemo-stagingkub postgresql-keycloak-0 -- \
  psql -U keycloak -d keycloak -c "SELECT id, name FROM realm;"

# Devrait afficher :
#                  id                  |  name
# --------------------------------------+--------
#  e4118a92-248b-4d3d-8859-251489aaa225 | master
#  <nouveau-id>                         | RHDemo

# Tester la connexion √† l'application
# https://rhdemo.stagingkub.local
```

---

## üõ°Ô∏è Solution permanente : Persistance des donn√©es

Pour √©viter que cela se reproduise, nous avons mis en place **extraMounts KinD**.

### Architecture de persistance

**Avant (donn√©es perdues au red√©marrage)** :
```
Host Machine
  ‚îî‚îÄ> Docker Container (rhdemo-control-plane)
       ‚îî‚îÄ> /var/local-path-provisioner/pvc-xxx  ‚ùå PERDU au restart
```

**Apr√®s (donn√©es persistantes)** :
```
Host Machine (/home/leno-vo/kind-data/rhdemo-stagingkub)  ‚úÖ PERSISTE
  ‚îî‚îÄ> extraMount ‚Üì
       Docker Container (rhdemo-control-plane)
         ‚îî‚îÄ> /var/local-path-provisioner  (li√© au host)
              ‚îî‚îÄ> pvc-xxx/  ‚úÖ PERSISTE
```

### Fichiers cr√©√©s/modifi√©s

1. **[kind-config.yaml](../infra/stagingkub/kind-config.yaml)** (nouveau)
   - Configuration KinD avec extraMounts
   - Monte `/home/leno-vo/kind-data/rhdemo-stagingkub` dans le node

2. **[init-stagingkub.sh](../infra/stagingkub/scripts/init-stagingkub.sh)** (modifi√©)
   - Utilise maintenant le fichier `kind-config.yaml` persistant
   - Cr√©e automatiquement le r√©pertoire de persistance sur l'h√¥te

### Recr√©er le cluster avec persistance

‚ö†Ô∏è **Attention** : Cela va d√©truire le cluster actuel et toutes ses donn√©es.

```bash
# 1. Sauvegarder les donn√©es actuelles
kubectl exec -n rhdemo-stagingkub postgresql-keycloak-0 -- \
  pg_dump -U keycloak keycloak > /tmp/keycloak-backup.sql

kubectl exec -n rhdemo-stagingkub postgresql-rhdemo-0 -- \
  pg_dump -U dbrhdemo dbrhdemo > /tmp/rhdemo-backup.sql

# 2. Supprimer le cluster actuel
kind delete cluster --name rhdemo

# 3. Recr√©er avec la nouvelle configuration persistante
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./init-stagingkub.sh

# 4. Red√©ployer l'application
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./deploy.sh 1.1.2-RELEASE  # (ou votre version)

# 5. Restaurer Keycloak
./init-keycloak-stagingkub.sh

# 6. Restaurer les donn√©es m√©tier
kubectl exec -i -n rhdemo-stagingkub postgresql-rhdemo-0 -- \
  psql -U dbrhdemo dbrhdemo < /tmp/rhdemo-backup.sql
```

### V√©rifier la persistance

```bash
# V√©rifier que le r√©pertoire de persistance existe sur l'h√¥te
ls -la /home/leno-vo/kind-data/rhdemo-stagingkub/

# V√©rifier le montage dans le node KinD
docker exec rhdemo-control-plane ls -la /var/local-path-provisioner/

# Devrait montrer les m√™mes fichiers (c'est le m√™me r√©pertoire)
```

---

## üöÄ Prochaine √©tape : CloudNativePG

Pour une gestion encore plus robuste des backups, voir [CLOUDNATIVEPG_MIGRATION.md](./CLOUDNATIVEPG_MIGRATION.md).

CloudNativePG apportera :
- ‚úÖ Backups automatiques quotidiens avec r√©tention
- ‚úÖ Point-In-Time Recovery (restaurer √† n'importe quel moment)
- ‚úÖ Haute disponibilit√© (replicas)
- ‚úÖ Pooling de connexions (PgBouncer)
- ‚úÖ Monitoring Prometheus int√©gr√©

---

## üìä Comparaison des solutions

| Solution | Survit au red√©marrage machine | Backups automatiques | PITR | HA | Complexit√© |
|----------|------------------------------|----------------------|------|-------|-----------|
| **StatefulSet actuel (sans extraMounts)** | ‚ùå NON | ‚ùå Non | ‚ùå Non | ‚ùå Non | Faible |
| **StatefulSet + extraMounts** | ‚úÖ OUI | ‚ùå Non (manuel) | ‚ùå Non | ‚ùå Non | Faible |
| **CloudNativePG + extraMounts** | ‚úÖ OUI | ‚úÖ Oui (quotidien) | ‚úÖ Oui | ‚úÖ Oui | Moyenne |

---

## üîß Commandes de diagnostic

### V√©rifier l'√©tat des PV/PVC

```bash
# Lister les PVC
kubectl get pvc -n rhdemo-stagingkub

# Voir les d√©tails d'un PVC
kubectl describe pvc postgresql-data-postgresql-keycloak-0 -n rhdemo-stagingkub

# Lister les PV avec leur politique de r√©tention
kubectl get pv -o custom-columns=NAME:.metadata.name,RECLAIM:.spec.persistentVolumeReclaimPolicy,STATUS:.status.phase
```

### V√©rifier les donn√©es dans PostgreSQL

```bash
# Connexion √† PostgreSQL Keycloak
kubectl exec -it -n rhdemo-stagingkub postgresql-keycloak-0 -- psql -U keycloak

# Lister les realms
SELECT id, name FROM realm;

# Lister les clients d'un realm
SELECT id, client_id FROM client WHERE realm_id = '<realm-id>';

# Lister les utilisateurs
SELECT id, username, email FROM user_entity WHERE realm_id = '<realm-id>';
```

### V√©rifier les √©v√©nements r√©cents

```bash
# √âv√©nements du namespace
kubectl get events -n rhdemo-stagingkub --sort-by='.lastTimestamp' | tail -20

# √âv√©nements d'un pod sp√©cifique
kubectl describe pod postgresql-keycloak-0 -n rhdemo-stagingkub | grep -A 10 Events
```

---

## üìù Checklist de recovery

### Apr√®s un red√©marrage machine (avec extraMounts)
- [ ] V√©rifier que le cluster KinD est d√©marr√© : `kind get clusters`
- [ ] V√©rifier que les pods sont Running : `kubectl get pods -n rhdemo-stagingkub`
- [ ] Tester l'acc√®s √† l'application : https://rhdemo.stagingkub.local
- [ ] V√©rifier la connexion avec un utilisateur de test

### Apr√®s un red√©marrage machine (SANS extraMounts)
- [ ] R√©initialiser Keycloak : `./init-keycloak-stagingkub.sh`
- [ ] Restaurer les donn√©es m√©tier si n√©cessaire (depuis backup manuel)
- [ ] **Action recommand√©e** : Recr√©er le cluster avec extraMounts (voir section ci-dessus)

---

## üí° Bonnes pratiques

### Backups manuels r√©guliers

En attendant CloudNativePG, faire des backups manuels r√©guliers :

```bash
# Script de backup √† ex√©cuter r√©guli√®rement
#!/bin/bash
BACKUP_DIR="/home/leno-vo/backups/stagingkub"
mkdir -p "$BACKUP_DIR"

DATE=$(date +%Y%m%d-%H%M%S)

# Backup Keycloak
kubectl exec -n rhdemo-stagingkub postgresql-keycloak-0 -- \
  pg_dump -U keycloak keycloak > "$BACKUP_DIR/keycloak-$DATE.sql"

# Backup RHDemo
kubectl exec -n rhdemo-stagingkub postgresql-rhdemo-0 -- \
  pg_dump -U dbrhdemo dbrhdemo > "$BACKUP_DIR/rhdemo-$DATE.sql"

# Compression
gzip "$BACKUP_DIR"/*.sql

# Rotation : garder 30 jours
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +30 -delete

echo "Backups cr√©√©s dans $BACKUP_DIR"
```

### Sauvegarde du r√©pertoire de persistance

Le r√©pertoire extraMounts peut √™tre sauvegard√© directement :

```bash
# Backup complet du r√©pertoire de persistance
tar -czf ~/backups/stagingkub-persistence-$(date +%Y%m%d).tar.gz \
  /home/leno-vo/kind-data/rhdemo-stagingkub

# Restauration
tar -xzf ~/backups/stagingkub-persistence-20260110.tar.gz -C /
```

---

## üìö Ressources

- [Configuration KinD](../infra/stagingkub/kind-config.yaml)
- [Script d'initialisation Keycloak](../infra/stagingkub/scripts/init-keycloak-stagingkub.sh)
- [Guide migration CloudNativePG](./CLOUDNATIVEPG_MIGRATION.md)
- [Documentation KinD extraMounts](https://kind.sigs.k8s.io/docs/user/configuration/#extra-mounts)

---

**Derni√®re mise √† jour** : 2026-01-10
