# INTÃ‰GRATION OBSERVABILITY STACK - ENVIRONMENT STAGINGKUB

**Date:** 22 janvier 2026
**Version:** 3.1 (Stack ComplÃ¨te: Prometheus + Loki + MÃ©triques Spring Boot Actuator)
**Environnement:** stagingkub (Kubernetes KinD)

**âš ï¸ SÃ©curitÃ©:** Consultez [/infra/stagingkub/SECURITY.md](../infra/stagingkub/SECURITY.md) pour les bonnes pratiques de configuration sÃ©curisÃ©e.

---

## TABLE DES MATIÃˆRES

1. [Vue d'ensemble](#1-vue-densemble)
2. [Architecture](#2-architecture)
3. [PrÃ©requis](#3-prÃ©requis)
4. [Installation](#4-installation)
5. [Configuration](#5-configuration)
6. [AccÃ¨s et Utilisation](#6-accÃ¨s-et-utilisation)
7. [Queries LogQL et PromQL](#7-queries-logql-et-promql)
8. [Dashboards Grafana](#8-dashboards-grafana)
9. [Troubleshooting](#9-troubleshooting)
10. [Maintenance](#10-maintenance)

---

## 1. VUE D'ENSEMBLE

### 1.1 Objectif

DÃ©ployer une stack d'observabilitÃ© complÃ¨te pour l'environnement stagingkub avec:
- **Prometheus + Operator**: Collecte et stockage des mÃ©triques (mÃ©triques applicatives, infrastructure, bases de donnÃ©es)
- **Loki**: SystÃ¨me d'agrÃ©gation et indexation des logs
- **Promtail**: Agent de collecte des logs (DaemonSet)
- **Grafana**: Interface unifiÃ©e de visualisation (mÃ©triques + logs)

### 1.2 Stack ComplÃ¨te (Prometheus + Loki + Grafana)

**Architecture de collecte:**
- **MÃ©triques**: Prometheus scrape les endpoints `/metrics` â†’ Stocke dans TSDB â†’ Grafana visualise
- **Logs**: Promtail collecte les logs â†’ Loki les stocke et indexe â†’ Grafana visualise

**Charts utilisÃ©s:**
- `prometheus-community/kube-prometheus-stack` (Prometheus + Operator + AlertManager)
- `grafana/loki` v6.x (mode SingleBinary)
- `grafana/promtail` v6.x
- `grafana/grafana` v8.x

### 1.3 BÃ©nÃ©fices

**MÃ©triques (Prometheus):**
âœ… MÃ©triques temps rÃ©el de tous les composants Kubernetes
âœ… MÃ©triques bases de donnÃ©es PostgreSQL
âœ… Alerting automatisÃ© via AlertManager
âœ… DÃ©tection automatique des PodMonitors/ServiceMonitors
âœ… Retention 7 jours, storage 10Gi

**Logs (Loki):**
âœ… Logs centralisÃ©s de tous les composants (rhDemo, Keycloak, PostgreSQL)
âœ… Recherche rapide avec LogQL (langage type PromQL)
âœ… RÃ©tention configurable des logs
âœ… Faible consommation ressources (comparÃ© Ã  ELK stack)
âœ… Pas de schÃ©ma rigide (indexation par labels uniquement)

**Grafana (Visualisation unifiÃ©e):**
âœ… Interface unique pour mÃ©triques ET logs
âœ… CorrÃ©lation mÃ©triques/logs (mÃªme timeline)
âœ… Dashboards prÃ©-configurÃ©s (rhDemo Logs)
âœ… Exploration interactive (Explore)

---

## 2. ARCHITECTURE

### 2.1 Composants DÃ©ployÃ©s

**Deux namespaces:**
- `monitoring`: Prometheus + Operator + AlertManager
- `loki-stack`: Loki + Promtail + Grafana

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Namespace: monitoring (MÃ‰TRIQUES)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Prometheus Operator (Deployment)                    â”‚  â”‚
â”‚  â”‚ - GÃ¨re automatiquement Prometheus/AlertManager      â”‚  â”‚
â”‚  â”‚ - Surveille les PodMonitors/ServiceMonitors        â”‚  â”‚
â”‚  â”‚ - CPU: 100m / Memory: 128Mi                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Prometheus Server (StatefulSet)                     â”‚  â”‚
â”‚  â”‚ - Service: prometheus-kube-prometheus-prometheus    â”‚  â”‚
â”‚  â”‚ - Port: 9090                                        â”‚  â”‚
â”‚  â”‚ - PVC: 10Gi (rÃ©tention 7j, 5GB max)               â”‚  â”‚
â”‚  â”‚ - Scrape interval: 30s                             â”‚  â”‚
â”‚  â”‚ - CPU: 200m / Memory: 512Mi                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ AlertManager (StatefulSet)                          â”‚  â”‚
â”‚  â”‚ - Gestion des alertes Prometheus                   â”‚  â”‚
â”‚  â”‚ - Port: 9093                                        â”‚  â”‚
â”‚  â”‚ - CPU: 50m / Memory: 64Mi                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Node Exporter (DaemonSet)                           â”‚  â”‚
â”‚  â”‚ - MÃ©triques des nodes Kubernetes                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Kube State Metrics (Deployment)                     â”‚  â”‚
â”‚  â”‚ - MÃ©triques des ressources Kubernetes              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Namespace: loki-stack (LOGS + VISUALISATION)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Promtail (DaemonSet)                                â”‚  â”‚
â”‚  â”‚ - 1 pod par node (KinD: 1 node control-plane)      â”‚  â”‚
â”‚  â”‚ - Lit /var/log/pods/**/*.log                       â”‚  â”‚
â”‚  â”‚ - Envoie Ã  Loki via HTTP (port 3100)              â”‚  â”‚
â”‚  â”‚ - CPU: 100m / Memory: 128Mi                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Loki (StatefulSet, replicas: 1)                    â”‚  â”‚
â”‚  â”‚ - Mode: SingleBinary                               â”‚  â”‚
â”‚  â”‚ - Service: loki-gateway:80 (ClusterIP)            â”‚  â”‚
â”‚  â”‚ - PVC: loki-data (5Gi, ReadWriteOnce)             â”‚  â”‚
â”‚  â”‚ - Stockage: filesystem (tsdb, schema v13)         â”‚  â”‚
â”‚  â”‚ - RÃ©tention: 168h (7 jours par dÃ©faut)            â”‚  â”‚
â”‚  â”‚ - CPU: 250m / Memory: 256Mi                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Grafana (Deployment, replicas: 1)                  â”‚  â”‚
â”‚  â”‚ - Service: grafana:80 (ClusterIP)                  â”‚  â”‚
â”‚  â”‚ - Ingress: grafana.stagingkub.local (HTTPS)       â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚ DataSources configurÃ©es:                           â”‚  â”‚
â”‚  â”‚ â€¢ Loki: http://loki-gateway:80                    â”‚  â”‚
â”‚  â”‚ â€¢ Prometheus: http://prometheus-kube-prometheus-  â”‚  â”‚
â”‚  â”‚               prometheus.monitoring.svc:9090       â”‚  â”‚
â”‚  â”‚                                                     â”‚  â”‚
â”‚  â”‚ - Admin: admin / (voir grafana-values.yaml)       â”‚  â”‚
â”‚  â”‚ - CPU: 250m / Memory: 256Mi                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Labels et MÃ©triques CollectÃ©s

**Labels Logs (Loki via Promtail):**

Promtail enrichit automatiquement les logs avec ces labels:

| Label | Exemple | Description |
|-------|---------|-------------|
| `namespace` | `rhdemo-stagingkub` | Namespace Kubernetes |
| `pod` | `rhdemo-app-7d8f9c6b-x5z2k` | Nom du pod |
| `container` | `rhdemo-app` | Nom du container |
| `app` | `rhdemo-app` | Label app |
| `job` | `rhdemo-stagingkub/rhdemo-app` | Namespace/app |
| `stream` | `stdout` ou `stderr` | Stream de sortie |

**MÃ©triques Prometheus:**

Prometheus collecte automatiquement via ServiceMonitors et PodMonitors:

| Source | MÃ©triques CollectÃ©es | Configuration |
|--------|---------------------|---------------|
| **Node Exporter** | MÃ©triques nodes (CPU, RAM, disque, rÃ©seau) | DaemonSet automatique |
| **Kube State Metrics** | Ã‰tat ressources K8s (pods, deployments, etc.) | Deployment automatique |
| **PostgreSQL** | MÃ©triques PostgreSQL (connexions, requÃªtes) | StatefulSet avec postgres_exporter (optionnel) |
| **Application rhDemo** | MÃ©triques Spring Boot Actuator (JVM, HTTP, HikariCP) | ServiceMonitor configurÃ© automatiquement |

### 2.3 Flux de DonnÃ©es

**Flux Logs:**
```
[rhdemo-app Pod] â†’ stdout/stderr â†’ /var/log/pods/rhdemo-stagingkub_rhdemo-app-xxx/
                                                    â†“
                                          [Promtail DaemonSet]
                                                    â†“
                                           Enrichissement labels
                                                    â†“
                                          HTTP POST â†’ [Loki Gateway:80]
                                                    â†“
                                            Indexation + Stockage
                                                    â†“
                                          [Grafana Explore] â† RequÃªte LogQL
```

**Flux MÃ©triques:**
```
[PostgreSQL Pod]      [Nodes]      [Pods K8s]
   :9187/metrics      :9100         kube-state-metrics
         â†“                â†“                â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
           [Prometheus Server] (scrape toutes les 30s)
                         â†“
              Stockage TSDB (7 jours)
                         â†“
           [Grafana] â† RequÃªtes PromQL
```

---

## 3. PRÃ‰REQUIS

### 3.1 Cluster Kubernetes

- âœ… Cluster KinD `rhdemo` dÃ©marrÃ©
- âœ… Namespace `rhdemo-stagingkub` existant
- âœ… Ingress Nginx Controller installÃ©

### 3.2 Outils Locaux

```bash
# VÃ©rifier installations
helm version  # v3.x requis
kubectl version --client  # v1.25+ recommandÃ©
kind version  # v0.20+
```

### 3.3 Ressources Disponibles

**Ressources totales requises pour Observability Stack complÃ¨te:**

**Namespace monitoring (Prometheus):**

| Composant | CPU Request | Memory Request | Storage |
|-----------|-------------|----------------|---------|
| Prometheus Operator | 100m | 128Mi | - |
| Prometheus Server | 200m | 512Mi | 10Gi (PVC) |
| AlertManager | 50m | 64Mi | 2Gi (PVC) |
| Node Exporter | ~20m | ~32Mi | - |
| Kube State Metrics | ~10m | ~64Mi | - |
| **Sous-total monitoring** | **~380m** | **~800Mi** | **12Gi** |

**Namespace loki-stack (Logs + Visualisation):**

| Composant | CPU Request | Memory Request | Storage |
|-----------|-------------|----------------|---------|
| Promtail | 100m | 128Mi | - |
| Loki | 250m | 256Mi | 5Gi (PVC) |
| Grafana | 250m | 256Mi | - |
| **Sous-total loki-stack** | **600m** | **640Mi** | **5Gi** |

**TOTAL OBSERVABILITY STACK:**

| Total | CPU Request | Memory Request | Storage |
|-------|-------------|----------------|---------|
| **Somme** | **~980m (~1 CPU)** | **~1.44Gi** | **17Gi** |

**VÃ©rifier ressources disponibles:**

```bash
kubectl top nodes  # Si metrics-server installÃ©
# OU
kubectl describe nodes rhdemo-control-plane | grep -A 5 "Allocated resources"
```

### 3.4 DNS Local

```bash
# Ajouter Ã  /etc/hosts
echo "127.0.0.1 grafana.stagingkub.local" | sudo tee -a /etc/hosts
```

---

## 4. INSTALLATION

### 4.1 Installation Automatique (RecommandÃ©e)

**âš ï¸ PRÃ‰REQUIS SÃ‰CURITÃ‰: Configurer le mot de passe Grafana**

Avant d'exÃ©cuter le script, vous **devez** configurer un mot de passe fort:

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability

# GÃ©nÃ©rer un mot de passe fort
PASSWORD=$(openssl rand -base64 32)
echo "Mot de passe gÃ©nÃ©rÃ©: $PASSWORD"

# Ã‰diter grafana-values.yaml et remplacer adminPassword: "" par le mot de passe
sed -i "s/adminPassword: \"\"/adminPassword: \"$PASSWORD\"/" grafana-values.yaml

# IMPORTANT: Sauvegarder ce mot de passe dans un gestionnaire de mots de passe
```

**Script d'installation clÃ© en main (Stack complÃ¨te):**

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./install-observability.sh
```

**Ce script installe la stack complÃ¨te (Prometheus + Loki + Grafana):**

**Namespace monitoring:**
- âœ… Prometheus Operator + Prometheus Server
- âœ… AlertManager (alertes)
- âœ… Node Exporter (mÃ©triques nodes)
- âœ… Kube State Metrics (mÃ©triques K8s)
- âœ… PodMonitor/ServiceMonitor auto-dÃ©tection

**Namespace loki-stack:**
- âœ… Loki (logs, mode SingleBinary)
- âœ… Promtail (collecte logs DaemonSet)
- âœ… Grafana (visualisation unifiÃ©e)
- âœ… Datasource Prometheus auto-configurÃ©e
- âœ… Datasource Loki auto-configurÃ©e
- âœ… Dashboards prÃ©-chargÃ©s (rhDemo Logs)

**Autres actions:**
- âœ… VÃ©rification des prÃ©requis (kubectl, helm, kind-rhdemo)
- âœ… Validation mot de passe Grafana
- âœ… Ajout repositories Helm (prometheus-community + grafana)
- âœ… CrÃ©ation namespaces (monitoring + loki-stack)
- âœ… GÃ©nÃ©ration certificat TLS Grafana
- âœ… Configuration DNS dans `/etc/hosts`

**DurÃ©e:** ~5-8 minutes

**AccÃ¨s aprÃ¨s installation:**
- **Grafana**: https://grafana.stagingkub.local (admin / voir grafana-values.yaml)
- **Prometheus**: `kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090`
- **AlertManager**: `kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093`

### 4.2 Installation Manuelle

#### 4.2.1 Ajouter les Repositories Helm

```bash
# Repository Prometheus Community
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

# Repository Grafana
helm repo add grafana https://grafana.github.io/helm-charts

# Mettre Ã  jour
helm repo update

# VÃ©rifier charts disponibles
helm search repo prometheus-community/kube-prometheus-stack
helm search repo grafana/loki
helm search repo grafana/promtail
helm search repo grafana/grafana
```

**Output attendu:**
```
NAME                                            CHART VERSION   APP VERSION     DESCRIPTION
prometheus-community/kube-prometheus-stack      65.x.x          v0.77.x         Prometheus Operator + Prometheus + ...
grafana/loki                                    6.x.x           3.x.x           Loki: like Prometheus, but for logs
grafana/promtail                                6.x.x           3.x.x           Promtail log collector
grafana/grafana                                 8.x.x           11.x.x          The open observability platform
```

#### 4.2.2 CrÃ©er les Namespaces

```bash
# Namespace pour Prometheus
kubectl create namespace monitoring

# Namespace pour Loki + Grafana
kubectl create namespace loki-stack

# VÃ©rifier
kubectl get namespaces | grep -E 'monitoring|loki'
```

#### 4.2.3 CrÃ©er les Fichiers de Configuration

Les fichiers de configuration sont dÃ©jÃ  prÃ©sents dans le projet:

**Prometheus:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/prometheus-values.yaml`

```yaml
# Configuration Prometheus + Operator
# Chart: prometheus-community/kube-prometheus-stack

prometheusOperator:
  enabled: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi

prometheus:
  enabled: true
  prometheusSpec:
    retention: 7d
    retentionSize: "5GB"
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    # â­ Important pour dÃ©couverte automatique de tous les PodMonitors
    podMonitorSelectorNilUsesHelmValues: false
    podMonitorSelector: {}  # Scrape TOUS les PodMonitors
    podMonitorNamespaceSelector: {}

    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}  # Scrape TOUS les ServiceMonitors

    scrapeInterval: 30s
    evaluationInterval: 30s

    resources:
      requests:
        cpu: 200m
        memory: 512Mi

# Grafana dÃ©sactivÃ© (installÃ© sÃ©parÃ©ment dans loki-stack)
grafana:
  enabled: false

alertmanager:
  enabled: true
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi

nodeExporter:
  enabled: true

kubeStateMetrics:
  enabled: true

# DÃ©sactiver composants non accessibles sur KinD
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
kubeEtcd:
  enabled: false
```

**Loki:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/loki-modern-values.yaml`

```yaml
# Configuration Loki moderne (chart grafana/loki)
# Chart: grafana/loki v6.x
deploymentMode: SingleBinary

loki:
  auth_enabled: false
  commonConfig:
    replication_factor: 1
  storage:
    type: 'filesystem'
  schemaConfig:
    configs:
      - from: "2024-01-01"
        store: tsdb
        object_store: filesystem
        schema: v13
        index:
          prefix: loki_index_
          period: 24h
  limits_config:
    retention_period: 168h  # 7 jours
    ingestion_rate_mb: 10
    ingestion_burst_size_mb: 20

singleBinary:
  replicas: 1
  resources:
    requests:
      cpu: 250m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: true
    size: 5Gi

# Services dÃ©sactivÃ©s (mode SingleBinary)
read:
  replicas: 0
write:
  replicas: 0
backend:
  replicas: 0
```

**Promtail:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/promtail-values.yaml`

```yaml
# Configuration Promtail
# Chart: grafana/promtail v6.x
config:
  clients:
    - url: http://loki-gateway/loki/api/v1/push
      tenant_id: ""
  positions:
    filename: /tmp/positions.yaml
  snippets:
    scrapeConfigs: |
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - rhdemo-stagingkub
        pipeline_stages:
          - cri: {}
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: .+
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - source_labels: [__meta_kubernetes_pod_label_app]
            target_label: app

resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi
```

**Grafana:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/grafana-values.yaml`

```yaml
# Configuration Grafana
# Chart: grafana/grafana v8.x

adminUser: admin
# âš ï¸ SÃ‰CURITÃ‰: DÃ©finir un mot de passe fort avant installation
adminPassword: ""  # TODO: Renseigner un mot de passe fort (openssl rand -base64 32)

resources:
  requests:
    cpu: 250m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

ingress:
  enabled: true
  ingressClassName: nginx
  hosts:
    - grafana.stagingkub.local
  tls:
    - secretName: grafana-tls-cert
      hosts:
        - grafana.stagingkub.local

datasources:
  datasources.yaml:
    apiVersion: 1
    datasources:
      - name: Loki
        type: loki
        access: proxy
        url: http://loki-gateway:80
        isDefault: true
        jsonData:
          maxLines: 1000
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus-kube-prometheus-prometheus.monitoring.svc:9090
        isDefault: false
        editable: true
        jsonData:
          timeInterval: 30s

grafana.ini:
  server:
    domain: grafana.stagingkub.local
    root_url: https://grafana.stagingkub.local
  analytics:
    reporting_enabled: false
    check_for_updates: false
  users:
    allow_sign_up: false
```

**âš ï¸ Avant de continuer:** Vous devez configurer le mot de passe Grafana:

```bash
# GÃ©nÃ©rer un mot de passe fort
PASSWORD=$(openssl rand -base64 32)

# Ã‰diter grafana-values.yaml et remplacer adminPassword: ""
sed -i "s/adminPassword: \"\"/adminPassword: \"$PASSWORD\"/" grafana-values.yaml

# Sauvegarder le mot de passe dans un gestionnaire de mots de passe
echo "Mot de passe Grafana: $PASSWORD"
```

#### 4.2.4 GÃ©nÃ©rer le Certificat TLS pour Grafana

```bash
# CrÃ©er rÃ©pertoire temporaire
TMP=$(mktemp -d)

# GÃ©nÃ©rer certificat self-signed
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout $TMP/tls.key \
  -out $TMP/tls.crt \
  -subj "/CN=grafana.stagingkub.local/O=RHDemo"

# CrÃ©er le secret dans Kubernetes
kubectl create secret tls grafana-tls-cert \
  --cert=$TMP/tls.crt \
  --key=$TMP/tls.key \
  -n loki-stack

# Nettoyer
rm -rf $TMP
```

#### 4.2.5 Installer les Charts

**Ordre d'installation: Prometheus â†’ Loki â†’ Promtail â†’ Grafana**

```bash
# 1. Installer Prometheus + Operator (namespace monitoring)
helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/prometheus-values.yaml \
  --wait --timeout 10m

# VÃ©rifier installation Prometheus
kubectl get pods -n monitoring
helm list -n monitoring

# 2. Installer Loki (mode SingleBinary)
helm upgrade --install loki grafana/loki \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/loki-modern-values.yaml \
  --wait --timeout 3m

# 3. Installer Promtail
helm upgrade --install promtail grafana/promtail \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/promtail-values.yaml \
  --wait --timeout 2m

# 4. Installer Grafana (avec les 2 datasources)
helm upgrade --install grafana grafana/grafana \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/grafana-values.yaml \
  --wait --timeout 3m

# VÃ©rifier les installations
helm list -n monitoring
helm list -n loki-stack
```

**Output attendu:**

```
# Namespace monitoring
NAME            NAMESPACE       REVISION        STATUS          CHART                              APP VERSION
prometheus      monitoring      1               deployed        kube-prometheus-stack-65.x.x       v0.77.x

# Namespace loki-stack
NAME            NAMESPACE       REVISION        STATUS          CHART                   APP VERSION
loki            loki-stack      1               deployed        loki-6.x.x              3.x.x
promtail        loki-stack      1               deployed        promtail-6.x.x          3.x.x
grafana         loki-stack      1               deployed        grafana-8.x.x           11.x.x
```

#### 4.2.6 VÃ©rifier le DÃ©ploiement

```bash
# VÃ©rifier pods Prometheus (namespace monitoring)
kubectl get pods -n monitoring

# Output attendu:
# NAME                                                   READY   STATUS    RESTARTS   AGE
# prometheus-kube-prometheus-operator-xxx                1/1     Running   0          5m
# prometheus-prometheus-kube-prometheus-prometheus-0     2/2     Running   0          5m
# alertmanager-prometheus-kube-prometheus-alertmanager-0 2/2     Running   0          5m
# prometheus-kube-state-metrics-xxx                      1/1     Running   0          5m
# prometheus-prometheus-node-exporter-xxx                1/1     Running   0          5m

# VÃ©rifier pods Loki Stack
kubectl get pods -n loki-stack

# Output attendu:
# NAME                            READY   STATUS    RESTARTS   AGE
# loki-0                          1/1     Running   0          2m
# promtail-xxxxx                  1/1     Running   0          2m
# grafana-xxxxx                   1/1     Running   0          2m

# VÃ©rifier les services (monitoring)
kubectl get svc -n monitoring

# VÃ©rifier les services (loki-stack)
kubectl get svc -n loki-stack

# Output attendu loki-stack:
# NAME              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
# loki-gateway      ClusterIP   10.96.xxx.xxx    <none>        80/TCP     2m
# grafana           ClusterIP   10.96.xxx.xxx    <none>        80/TCP     2m

# VÃ©rifier l'ingress
kubectl get ingress -n loki-stack

# VÃ©rifier les PVCs (deux namespaces)
kubectl get pvc -n monitoring
kubectl get pvc -n loki-stack

# VÃ©rifier les PodMonitors
kubectl get podmonitor -A

# VÃ©rifier les ServiceMonitors
kubectl get servicemonitor -A
```

#### 4.2.7 VÃ©rifier la Collecte des Logs

```bash
# Port-forward Loki Gateway pour tester
kubectl port-forward -n loki-stack svc/loki-gateway 3100:80 &

# Interroger Loki directement (via API)
curl -G -s "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={namespace="rhdemo-stagingkub"}' \
  | jq '.data.result'

# Si des logs sont prÃ©sents, vous verrez un JSON avec les streams

# VÃ©rifier les labels disponibles
curl -s "http://localhost:3100/loki/api/v1/labels" | jq

# ArrÃªter le port-forward
kill %1
```

---

## 5. CONFIGURATION

### 5.1 Ajouter Grafana au DNS Local

```bash
# DÃ©jÃ  ajoutÃ© en prÃ©requis, vÃ©rifier
grep grafana.stagingkub.local /etc/hosts

# Si absent:
echo "127.0.0.1 grafana.stagingkub.local" | sudo tee -a /etc/hosts
```

### 5.2 Ajuster la RÃ©tention des Logs

Par dÃ©faut: **7 jours** (168h).

**Pour modifier:**

Ã‰diter `loki-modern-values.yaml`:

```yaml
loki:
  limits_config:
    retention_period: 336h  # 14 jours au lieu de 7
```

**Appliquer:**

```bash
helm upgrade loki grafana/loki \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/loki-modern-values.yaml
```

### 5.3 Augmenter les Ressources (si nÃ©cessaire)

Si vous avez beaucoup de logs (>100MB/jour):

```yaml
# loki-modern-values.yaml
singleBinary:
  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  persistence:
    size: 10Gi  # Augmenter stockage

loki:
  limits_config:
    ingestion_rate_mb: 20
    ingestion_burst_size_mb: 40
```

### 5.4 Dashboard rhDemo PrÃ©-configurÃ© (DÃ©ploiement Automatique)

**âœ… DÃ©ploiement automatique lors de l'installation**

Le script `install-loki.sh` dÃ©ploie automatiquement le dashboard "rhDemo - Logs Application". Aucune action manuelle requise!

**Dashboard inclus:**
- ğŸ”´ **Logs d'Erreurs** : Logs contenant "ERROR"
- ğŸ“Š **Rate d'Erreurs** : Nombre d'erreurs par minute
- ğŸ“ˆ **Volume de Logs** : Volume par application
- ğŸ” **Logs Temps RÃ©el** : Tous les logs de l'app
- ğŸ” **Logs Keycloak** : Authentification
- ğŸ—„ï¸ **Logs PostgreSQL** : Logs des bases de donnÃ©es
- âš ï¸ **Compteur WARN** : Logs WARNING derniÃ¨re heure
- ğŸ”´ **Compteur ERROR** : Logs ERROR derniÃ¨re heure
- ğŸ“Š **Top 10 Pods** : Pods avec le plus de logs

**Fichier source:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/grafana-dashboard-rhdemo.json`

**Mise Ã  jour manuelle du dashboard:**

Si vous modifiez le fichier JSON et souhaitez redÃ©ployer sans rÃ©installer toute la stack :

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./deploy-grafana-dashboard.sh
```

**Documentation complÃ¨te:** Voir [GRAFANA_DASHBOARD.md](../infra/stagingkub/GRAFANA_DASHBOARD.md)

---

## 6. ACCÃˆS ET UTILISATION

### 6.1 AccÃ©der Ã  Grafana

**URL:** https://grafana.stagingkub.local

**Credentials:**
- Username: `admin`
- Password: (mot de passe configurÃ© dans grafana-values.yaml)

**Navigation:**
1. Menu â†’ Explore
2. SÃ©lectionner datasource: **Loki** (logs) ou **Prometheus** (mÃ©triques)
3. Construire requÃªte LogQL ou PromQL

### 6.2 AccÃ©der Ã  Prometheus (optionnel)

```bash
# Port-forward vers Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090

# AccÃ©der Ã  http://localhost:9090
```

**URL:** http://localhost:9090

**Features:**
- Status â†’ Targets (vÃ©rifier tous les scrapes)
- Status â†’ Service Discovery (vÃ©rifier PodMonitors/ServiceMonitors)
- Graph (requÃªtes PromQL manuelles)

### 6.3 AccÃ©der Ã  AlertManager (optionnel)

```bash
# Port-forward vers AlertManager
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093

# AccÃ©der Ã  http://localhost:9093
```

### 6.4 Interface Grafana Explore

**Ã‰lÃ©ments clÃ©s:**

| Ã‰lÃ©ment | Description |
|---------|-------------|
| **Datasource** | Loki (logs) ou Prometheus (mÃ©triques) |
| **Query Editor** | Construire requÃªte LogQL ou PromQL |
| **Log Browser** | (Loki) Labels disponibles (namespace, pod, app, etc.) |
| **Metric Browser** | (Prometheus) MÃ©triques disponibles |
| **Time Range** | SÃ©lecteur pÃ©riode (Last 5m, Last 1h, etc.) |
| **Live** | Tail logs en temps rÃ©el (Loki) |
| **Log Details** | Clic sur une ligne â†’ dÃ©tails + labels |
| **Split View** | Comparer logs et mÃ©triques cÃ´te Ã  cÃ´te |

### 6.3 Modes de Recherche

#### Mode Builder (RecommandÃ© pour dÃ©buter)

1. Cliquer sur "Log browser"
2. SÃ©lectionner labels:
   - `namespace` = `rhdemo-stagingkub`
   - `app` = `rhdemo-app`
3. Cliquer "Show logs"

#### Mode Code (LogQL avancÃ©)

Ã‰crire directement la requÃªte LogQL:

```logql
{namespace="rhdemo-stagingkub", app="rhdemo-app"}
```

---

## 7. QUERIES LOGQL ET PROMQL

### 7.1 Queries LogQL (Logs avec Loki)

#### 7.1.1 Logs par Composant

**Tous les logs rhDemo app:**
```logql
{namespace="rhdemo-stagingkub", app="rhdemo-app"}
```

**Logs Keycloak uniquement:**
```logql
{namespace="rhdemo-stagingkub", app="keycloak"}
```

**Logs PostgreSQL rhDemo:**
```logql
{namespace="rhdemo-stagingkub", app="postgresql-rhdemo"}
```

**Logs PostgreSQL Keycloak:**
```logql
{namespace="rhdemo-stagingkub", app="postgresql-keycloak"}
```

### 7.2 Filtres par Mot-clÃ©

**Rechercher "ERROR":**
```logql
{namespace="rhdemo-stagingkub"} |= "ERROR"
```

**Rechercher "Exception" (case-insensitive):**
```logql
{namespace="rhdemo-stagingkub"} |~ "(?i)exception"
```

**Exclure logs contenant "health":**
```logql
{namespace="rhdemo-stagingkub"} != "health"
```

**Logs contenant "SQL" MAIS PAS "SELECT":**
```logql
{namespace="rhdemo-stagingkub"} |= "SQL" != "SELECT"
```

### 7.3 Logs d'Erreurs Spring Boot

**Stack traces Java:**
```logql
{namespace="rhdemo-stagingkub", app="rhdemo-app"} |~ "Exception|Error"
```

**Logs niveau ERROR:**
```logql
{namespace="rhdemo-stagingkub", app="rhdemo-app"} |= "ERROR"
```

**Logs d'une classe spÃ©cifique:**
```logql
{namespace="rhdemo-stagingkub", app="rhdemo-app"} |~ "EmployeService"
```

### 7.4 Logs d'Authentification Keycloak

**Logins rÃ©ussis:**
```logql
{namespace="rhdemo-stagingkub", app="keycloak"} |~ "Login|authenticated"
```

**Ã‰checs d'authentification:**
```logql
{namespace="rhdemo-stagingkub", app="keycloak"} |~ "Invalid|failed.*login"
```

**ActivitÃ© utilisateur "admil":**
```logql
{namespace="rhdemo-stagingkub", app="keycloak"} |~ "admil"
```

### 7.5 Logs PostgreSQL

**RequÃªtes lentes (>1s):**
```logql
{namespace="rhdemo-stagingkub", app=~"postgresql-.*"} |~ "duration.*[1-9][0-9]{3,} ms"
```

**Erreurs SQL:**
```logql
{namespace="rhdemo-stagingkub", app=~"postgresql-.*"} |~ "ERROR"
```

**Connexions/dÃ©connexions:**
```logql
{namespace="rhdemo-stagingkub", app=~"postgresql-.*"} |~ "connection.*authorized|disconnection"
```

### 7.6 AgrÃ©gations et MÃ©triques

**Compter les logs ERROR par minute:**
```logql
sum(count_over_time({namespace="rhdemo-stagingkub"} |= "ERROR" [1m]))
```

**Rate de logs par app:**
```logql
sum by (app) (rate({namespace="rhdemo-stagingkub"}[5m]))
```

**Top 10 pods par volume de logs:**
```logql
topk(10, sum by (pod) (count_over_time({namespace="rhdemo-stagingkub"}[1h])))
```

#### 7.1.6 Logs en Temps RÃ©el (Live Tail)

**Bouton "Live" dans Grafana Explore** OU:

```bash
# Via CLI (logcli)
logcli query --tail '{namespace="rhdemo-stagingkub", app="rhdemo-app"}'
```

### 7.2 Queries PromQL (MÃ©triques avec Prometheus)

#### 7.2.1 MÃ©triques Kubernetes (Kube State Metrics)

**Pods en cours d'exÃ©cution par namespace:**
```promql
kube_pod_status_phase{namespace="rhdemo-stagingkub", phase="Running"}
```

**Pods en erreur:**
```promql
kube_pod_status_phase{namespace="rhdemo-stagingkub", phase=~"Failed|Unknown"}
```

**Nombre de restarts de containers:**
```promql
kube_pod_container_status_restarts_total{namespace="rhdemo-stagingkub"}
```

**Deployments avec replicas disponibles:**
```promql
kube_deployment_status_replicas_available{namespace="rhdemo-stagingkub"}
```

#### 7.2.3 MÃ©triques Nodes (Node Exporter)

**CPU utilisÃ© par node (%):**
```promql
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

**MÃ©moire utilisÃ©e (%):**
```promql
100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))
```

**Espace disque utilisÃ© (%):**
```promql
100 - ((node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100)
```

**Network traffic (bytes/sec):**
```promql
rate(node_network_receive_bytes_total[5m])
rate(node_network_transmit_bytes_total[5m])
```

#### 7.2.4 MÃ©triques Application Spring Boot Actuator

Les mÃ©triques Spring Boot Actuator sont collectÃ©es automatiquement via le ServiceMonitor `rhdemo-app` dÃ©ployÃ© dans le namespace `monitoring`.

**Configuration requise:**

- Endpoint `/actuator/prometheus` exposÃ© sans authentification (protÃ©gÃ© par NetworkPolicy)
- ServiceMonitor configurÃ© dans le chart Helm `rhdemo`
- Label `environment=stagingkub` ajoutÃ© aux mÃ©triques

**JVM Heap Memory:**
```promql
sum(jvm_memory_used_bytes{environment="stagingkub", area="heap"}) / 1024 / 1024
```

**JVM Threads actifs:**
```promql
jvm_threads_live_threads{environment="stagingkub"}
```

**RequÃªtes HTTP par seconde:**
```promql
sum(rate(http_server_requests_seconds_count{environment="stagingkub"}[5m]))
```

**Latence HTTP p50/p95/p99:**
```promql
histogram_quantile(0.95, sum by (le) (rate(http_server_requests_seconds_bucket{environment="stagingkub"}[5m])))
```

**Erreurs HTTP 4xx/5xx:**
```promql
sum(rate(http_server_requests_seconds_count{environment="stagingkub", status=~"4.."}[5m]))
sum(rate(http_server_requests_seconds_count{environment="stagingkub", status=~"5.."}[5m]))
```

**Connexions HikariCP actives:**
```promql
hikaricp_connections_active{environment="stagingkub"}
```

**Pool HikariCP complet:**
```promql
hikaricp_connections{environment="stagingkub"}
hikaricp_connections_idle{environment="stagingkub"}
hikaricp_connections_pending{environment="stagingkub"}
hikaricp_connections_max{environment="stagingkub"}
```

**Garbage Collection:**
```promql
rate(jvm_gc_pause_seconds_sum{environment="stagingkub"}[5m])
```

**Logs par niveau (Logback):**
```promql
rate(logback_events_total{environment="stagingkub", level="error"}[5m])
```

---

## 8. DASHBOARDS GRAFANA

### 8.1 Dashboard rhDemo - Logs d'Application (PrÃ©-configurÃ©)

**âœ… Dashboard automatiquement disponible aprÃ¨s installation!**

Le dashboard "rhDemo - Logs Application" est dÃ©ployÃ© automatiquement lors de l'installation de la stack Loki.

**AccÃ¨s:** Grafana â†’ Dashboards â†’ "rhDemo - Logs Application"

**Contenu du dashboard:**

| Panel | Description | Query |
|-------|-------------|-------|
| ğŸ”´ **Logs d'Erreurs** | Logs contenant ERROR | `{namespace="rhdemo-stagingkub", app="rhdemo-app"} \|= "ERROR"` |
| ğŸ“Š **Rate d'Erreurs** | Erreurs par minute | `sum(count_over_time({...} \|= "ERROR" [1m]))` |
| ğŸ“ˆ **Volume de Logs** | Volume par app (rate 5min) | `sum by (app) (rate({namespace="rhdemo-stagingkub"}[5m]))` |
| ï¿½ï¿½ **Logs Temps RÃ©el** | Tous les logs de l'app | `{namespace="rhdemo-stagingkub", app="rhdemo-app"}` |
| ğŸ” **Logs Keycloak** | Authentification | `{..., app="keycloak"} \|~ "Login\|logout\|authenticated"` |
| ğŸ—„ï¸ **Logs PostgreSQL** | Logs database | `{..., app=~"postgresql-.*"}` |
| ğŸ“Š **Top 10 Pods** | Pods avec le plus de logs | `topk(10, sum by (pod) (count_over_time({...}[1h])))` |
| âš ï¸ **Logs WARN** | Compteur WARNING (1h) | `sum(count_over_time({...} \|= "WARN" [1h]))` |
| ğŸ”´ **Logs ERROR** | Compteur ERROR (1h) | `sum(count_over_time({...} \|= "ERROR" [1h]))` |

**Personnalisation:**

Pour modifier le dashboard:
1. Dupliquer le dashboard (Dashboard â†’ Settings â†’ Save As)
2. Modifier la copie selon vos besoins
3. Le dashboard original reste disponible

Pour dÃ©ployer une nouvelle version du dashboard source:
```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./deploy-grafana-dashboard.sh
```

**Documentation complÃ¨te:** [GRAFANA_DASHBOARD.md](../infra/stagingkub/GRAFANA_DASHBOARD.md)

### 8.2 Dashboard rhDemo - MÃ©triques Spring Boot Actuator (PrÃ©-configurÃ©)

**Dashboard automatiquement disponible aprÃ¨s installation!**

Le dashboard "rhDemo - Metriques Spring Boot Actuator" affiche les mÃ©triques JVM, HTTP et HikariCP collectÃ©es via `/actuator/prometheus`.

**AccÃ¨s:** Grafana â†’ Dashboards â†’ "rhDemo - Metriques Spring Boot Actuator"

**PrÃ©requis:**

- ServiceMonitor `rhdemo-app` dÃ©ployÃ© dans le namespace `monitoring`
- Endpoint `/actuator/prometheus` accessible sans authentification
- NetworkPolicy autorisant le scraping depuis le namespace `monitoring`

**Contenu du dashboard:**

| Section | Panels | MÃ©triques |
|---------|--------|-----------|
| **Vue d'ensemble** | Heap %, Threads, Req/s, DB Active | Stats instantanÃ©es |
| **JVM Memory** | Heap Used/Committed/Max, Non-Heap, Par Pool | `jvm_memory_*` |
| **JVM Threads** | Par Ã©tat, Live/Daemon/Peak | `jvm_threads_*` |
| **Garbage Collection** | DurÃ©e GC par action/cause | `jvm_gc_pause_*` |
| **HTTP Requests** | Req/s par status, Latence p50/p95/p99, Par endpoint, Erreurs 4xx/5xx | `http_server_requests_*` |
| **HikariCP** | Active/Idle/Pending/Total/Max, Acquire/Creation Time | `hikaricp_*` |
| **Logback** | Events par niveau (ERROR/WARN/INFO), Uptime | `logback_events_*`, `process_uptime_*` |

**Fichier source:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/grafana-dashboard-rhdemo-springboot.json`

**DÃ©ploiement:**

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./deploy-grafana-dashboard.sh springboot
# ou pour tous les dashboards:
./deploy-grafana-dashboard.sh all
```

**Configuration ServiceMonitor (Helm):**

Le ServiceMonitor est automatiquement crÃ©Ã© lors du dÃ©ploiement du chart Helm `rhdemo` si `rhdemo.metrics.serviceMonitor.enabled: true` dans `values.yaml`.

```yaml
# values.yaml
rhdemo:
  metrics:
    serviceMonitor:
      enabled: true
      namespace: monitoring
      interval: 30s
      scrapeTimeout: 10s
```

**Fichiers associÃ©s:**

- ServiceMonitor: `infra/stagingkub/helm/rhdemo/templates/servicemonitor-rhdemo.yaml`
- NetworkPolicy: `infra/stagingkub/helm/rhdemo/templates/networkpolicy-prometheus.yaml`
- Dashboard: `infra/stagingkub/grafana-dashboard-rhdemo-springboot.json`

### 8.3 Dashboard rhDemo - MÃ©triques PostgreSQL (PrÃ©-configurÃ©)

**Dashboard automatiquement disponible aprÃ¨s installation!**

Le dashboard "rhDemo - MÃ©triques PostgreSQL" affiche les mÃ©triques de performance de la base de donnÃ©es collectÃ©es via `postgres_exporter` et `pg_stat_statements`.

**AccÃ¨s:** Grafana â†’ Dashboards â†’ "rhDemo - Metriques PostgreSQL"

**PrÃ©requis:**

- Sidecar `postgres_exporter` dÃ©ployÃ© avec le StatefulSet PostgreSQL
- Extension `pg_stat_statements` activÃ©e dans PostgreSQL
- ServiceMonitor `postgresql-rhdemo` dÃ©ployÃ© dans le namespace `monitoring`

**Contenu du dashboard:**

| Section | Panels | MÃ©triques |
|---------|--------|-----------|
| **Vue d'ensemble** | Taille DB, Connexions, Verrous, Dead Tuples, RequÃªtes Longues | Stats instantanÃ©es |
| **Top 10 RequÃªtes Lentes** | Table avec temps total, temps moyen, appels, lignes | `pg_stat_statements_*` |
| **Statistiques RequÃªtes** | Temps moyen par requÃªte, Appels par requÃªte | `pg_stat_statements_*` |
| **Connexions & ActivitÃ©** | Par Ã©tat (active/idle), Verrous par mode | `pg_stat_activity_*`, `pg_locks_*` |
| **Statistiques Tables** | OpÃ©rations CRUD, Scans seq vs index, Live/Dead tuples | `pg_stat_user_tables_*` |
| **Cache & I/O** | Cache Hit Ratio, Shared Blocks Hit vs Read | `pg_stat_statements_shared_blks_*` |

**Fichier source:** `/home/leno-vo/git/repository/rhDemo/infra/stagingkub/grafana-dashboard-rhdemo-postgresql.json`

**DÃ©ploiement:**

```bash
cd /home/leno-vo/git/repository/rhDemo/infra/stagingkub/scripts
./deploy-grafana-dashboard.sh postgresql
# ou pour tous les dashboards:
./deploy-grafana-dashboard.sh all
```

**Configuration postgres_exporter (Helm):**

Le sidecar postgres_exporter est automatiquement dÃ©ployÃ© si `postgresql-rhdemo.metrics.enabled: true` dans `values.yaml`.

```yaml
# values.yaml
postgresql-rhdemo:
  metrics:
    enabled: true
    exporter:
      image:
        repository: quay.io/prometheuscommunity/postgres-exporter
        tag: "v0.15.0"
    serviceMonitor:
      enabled: true
      namespace: monitoring
      interval: 30s
      scrapeTimeout: 10s
```

**Fichiers associÃ©s:**

- StatefulSet avec sidecar: `infra/stagingkub/helm/rhdemo/templates/postgresql-rhdemo-statefulset.yaml`
- RequÃªtes personnalisÃ©es: `infra/stagingkub/helm/rhdemo/templates/postgres-exporter-queries-configmap.yaml`
- ServiceMonitor: `infra/stagingkub/helm/rhdemo/templates/servicemonitor-postgresql.yaml`
- Dashboard: `infra/stagingkub/grafana-dashboard-rhdemo-postgresql.json`

**RequÃªtes PromQL utiles:**

Top 10 requÃªtes les plus lentes (temps total):

```promql
topk(10, pg_stat_statements_total_time_seconds{environment="stagingkub"})
```

Temps moyen par requÃªte:

```promql
pg_stat_statements_mean_time_seconds{environment="stagingkub"}
```

Connexions par Ã©tat:

```promql
pg_stat_activity_connections{environment="stagingkub"}
```

Cache Hit Ratio:

```promql
sum(pg_stat_statements_shared_blks_hit) / (sum(pg_stat_statements_shared_blks_hit) + sum(pg_stat_statements_shared_blks_read) + 1)
```

### 8.4 Dashboard Keycloak - Logs d'Authentification (Custom)

**Query principale:**
```logql
{namespace="rhdemo-stagingkub", app="keycloak"}
```

**Panels:**

| Panel | Query | MÃ©trique |
|-------|-------|----------|
| **Login Rate** | `sum(rate({app="keycloak"} \|~ "Login" [5m]))` | Logins/sec |
| **Failed Logins** | `sum(count_over_time({app="keycloak"} \|~ "failed.*login" [1h]))` | Total failures |
| **Active Users** | Extraction custom via `\| regexp "user=(?P<user>\\w+)"` | Unique users |

### 8.5 Dashboard PostgreSQL - Logs des Bases de DonnÃ©es (Loki)

**Query principale:**
```logql
{namespace="rhdemo-stagingkub", app=~"postgresql-.*"}
```

**Panels:**

| Panel | Query | MÃ©trique |
|-------|-------|----------|
| **Slow Queries** | `{app=~"postgresql-.*"} \|~ "duration.*[1-9][0-9]{3,} ms"` | RequÃªtes >1s |
| **Connection Pool** | Extraction connections actives | Connections |
| **Error Log** | `{app=~"postgresql-.*"} \|= "ERROR"` | Erreurs SQL |

### 8.4 Dashboard ConsolidÃ© - Vue d'Ensemble

**Variables:**

CrÃ©er variables pour filtrer dynamiquement:

| Variable | Query | Type |
|----------|-------|------|
| `$app` | `label_values(app)` | Multi-select |
| `$pod` | `label_values({namespace="rhdemo-stagingkub"}, pod)` | Multi-select |

**Query utilisant variables:**
```logql
{namespace="rhdemo-stagingkub", app=~"$app", pod=~"$pod"}
```

### 8.5 Exporter/Importer Dashboard

**Exporter:**

1. Dashboard â†’ Settings â†’ JSON Model
2. Copier JSON
3. Sauvegarder dans `/infra/stagingkub/grafana-dashboards/rhdemo-logs.json`

**Importer:**

1. Dashboards â†’ Import
2. Upload JSON file
3. SÃ©lectionner datasource: Loki

---

## 9. TROUBLESHOOTING

### 9.1 Loki ne DÃ©marre Pas

**SymptÃ´me:** Pod `loki-0` en CrashLoopBackOff

**VÃ©rification:**

```bash
kubectl logs -n loki-stack loki-0
kubectl describe pod -n loki-stack loki-0
```

**Causes frÃ©quentes:**

| Erreur | Solution |
|--------|----------|
| "permission denied /loki/chunks" | VÃ©rifier PVC permissions: `securityContext.fsGroup: 10001` |
| "out of memory" | Augmenter memory limits dans values.yaml |
| "cannot bind :3100" | Port dÃ©jÃ  utilisÃ© (vÃ©rifier autre Loki) |

**Fix permissions PVC:**

```bash
# Ajouter Ã  loki-stack-values.yaml
loki:
  podSecurityContext:
    fsGroup: 10001
  containerSecurityContext:
    runAsUser: 10001
    runAsNonRoot: true
```

### 9.2 Promtail ne Collecte Pas de Logs

**SymptÃ´me:** Aucun log dans Grafana

**VÃ©rification:**

```bash
# Logs Promtail
kubectl logs -n loki-stack -l app=promtail

# VÃ©rifier que Promtail trouve des pods
kubectl logs -n loki-stack -l app=promtail | grep "discovered"
```

**Causes frÃ©quentes:**

| ProblÃ¨me | Solution |
|----------|----------|
| Namespace filter trop strict | VÃ©rifier `scrape_configs.relabel_configs` dans values.yaml |
| Promtail ne peut pas lire /var/log/pods | VÃ©rifier mountPath et hostPath dans DaemonSet |
| Logs en JSON non parsÃ©s | Ajouter pipeline stage `json` dans Promtail config |

**VÃ©rifier collecte manuelle:**

```bash
# Exec dans Promtail
kubectl exec -n loki-stack -it loki-stack-promtail-xxxxx -- sh

# Lister logs accessibles
ls -la /var/log/pods/rhdemo-stagingkub*/

# Tail un log
tail -f /var/log/pods/rhdemo-stagingkub_rhdemo-app-*/rhdemo-app/*.log
```

### 9.3 Prometheus ne Scrape Pas les MÃ©triques

**SymptÃ´me:** MÃ©triques PostgreSQL ou autres absentes dans Grafana

**VÃ©rification:**

```bash
# VÃ©rifier pods Prometheus
kubectl get pods -n monitoring

# VÃ©rifier les targets Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090

# AccÃ©der Ã  http://localhost:9090/targets
# Chercher les targets en Ã©tat "DOWN"
```

**VÃ©rifier PodMonitors/ServiceMonitors:**

```bash
# Lister tous les PodMonitors
kubectl get podmonitor -A

# Lister tous les ServiceMonitors
kubectl get servicemonitor -A

# VÃ©rifier logs Prometheus Operator
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus-operator
```

**Causes frÃ©quentes:**

| ProblÃ¨me | Solution |
|----------|----------|
| `podMonitorSelector` trop restrictif | VÃ©rifier `podMonitorSelector: {}` dans prometheus-values.yaml |
| PodMonitor dans mauvais namespace | VÃ©rifier `podMonitorNamespaceSelector: {}` |
| Port mÃ©trique incorrect | VÃ©rifier que le pod expose bien le port des mÃ©triques |
| Network policy bloque scrape | VÃ©rifier network policies entre namespaces |

**Test manuel scrape:**

```bash
# Port-forward vers un pod avec mÃ©triques
kubectl port-forward -n rhdemo-stagingkub <pod-name> <metrics-port>:<metrics-port>

# VÃ©rifier mÃ©triques exposÃ©es
curl http://localhost:<metrics-port>/metrics
```

### 9.4 Grafana - Datasource Loki ou Prometheus Inaccessible

**SymptÃ´me Loki:** "Data source connected, but no labels received"
**SymptÃ´me Prometheus:** "Data source is working" mais pas de mÃ©triques

**VÃ©rification:**

```bash
# Tester connexion depuis pod Grafana
kubectl exec -n loki-stack -it deployment/grafana -- sh

# Curl Loki
wget -O- http://loki-gateway:80/ready

# Tester API labels Loki
wget -O- http://loki-gateway:80/loki/api/v1/labels

# Curl Prometheus
wget -O- http://prometheus-kube-prometheus-prometheus.monitoring.svc:9090/-/healthy

# Tester query Prometheus
wget -O- 'http://prometheus-kube-prometheus-prometheus.monitoring.svc:9090/api/v1/query?query=up'
```

**Solution:**

VÃ©rifier que les services existent:

```bash
# Service Loki
kubectl get svc -n loki-stack loki-gateway

# Service Prometheus
kubectl get svc -n monitoring prometheus-kube-prometheus-prometheus
```

**Reconfigurer datasource Prometheus si nÃ©cessaire:**

```bash
# CrÃ©er ConfigMap pour datasource Prometheus
cat <<EOF | kubectl apply -n loki-stack -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasource-prometheus
  labels:
    grafana_datasource: "1"
data:
  prometheus-datasource.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus-kube-prometheus-prometheus.monitoring.svc:9090
        isDefault: false
        editable: true
EOF

# RedÃ©marrer Grafana
kubectl rollout restart deployment/grafana -n loki-stack
```

### 9.5 Ingress Grafana ne Fonctionne Pas

**SymptÃ´me:** `curl https://grafana.stagingkub.local` timeout

**VÃ©rification:**

```bash
# VÃ©rifier Ingress
kubectl get ingress -n loki-stack

# VÃ©rifier annotations
kubectl describe ingress -n loki-stack loki-stack-grafana

# VÃ©rifier service Grafana
kubectl get svc -n loki-stack loki-stack-grafana
```

**Solutions:**

1. **VÃ©rifier Nginx Ingress Controller:**
   ```bash
   kubectl get pods -n ingress-nginx
   ```

2. **VÃ©rifier TLS secret:**
   ```bash
   kubectl get secret -n loki-stack grafana-tls-cert
   ```

3. **Port-forward temporaire:**
   ```bash
   kubectl port-forward -n loki-stack svc/loki-stack-grafana 3000:80
   # AccÃ©der: http://localhost:3000
   ```

### 9.6 Logs Trop Volumineux (PVC Plein)

**SymptÃ´me:** Loki ne peut plus Ã©crire

**VÃ©rification:**

```bash
# VÃ©rifier utilisation PVC
kubectl exec -n loki-stack loki-0 -- df -h /loki

# Output:
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/xxx        5.0G  4.9G  100M  98% /loki
```

**Solutions:**

1. **Augmenter PVC (si storage class supporte):**
   ```bash
   kubectl patch pvc -n loki-stack loki-data \
     -p '{"spec":{"resources":{"requests":{"storage":"10Gi"}}}}'
   ```

2. **RÃ©duire rÃ©tention:**
   ```yaml
   # loki-modern-values.yaml
   loki:
     limits_config:
       retention_period: 72h  # 3 jours au lieu de 7
   ```

3. **Forcer compaction:**
   ```bash
   # RedÃ©marrer Loki (force compaction)
   kubectl rollout restart statefulset -n loki-stack loki
   ```

### 9.7 RequÃªtes LogQL Lentes

**SymptÃ´me:** Timeout ou >10s pour afficher logs

**Optimisations:**

1. **Limiter time range:**
   - Utiliser "Last 1h" au lieu de "Last 24h"

2. **Ajouter plus de labels:**
   ```logql
   # LENT (scan tous namespaces)
   {app="rhdemo-app"}

   # RAPIDE (scan 1 namespace)
   {namespace="rhdemo-stagingkub", app="rhdemo-app"}
   ```

3. **Augmenter ressources Loki:**
   ```yaml
   # loki-modern-values.yaml
   singleBinary:
     resources:
       limits:
         cpu: 1000m
         memory: 1Gi
   ```

---

## 10. MAINTENANCE

### 10.1 Backup des Logs

**StratÃ©gie:**

Loki stocke dans PVC `loki-data`. Pour backup:

```bash
# CrÃ©er backup du PVC
kubectl exec -n loki-stack loki-0 -- tar czf /tmp/loki-backup.tar.gz /loki/chunks /loki/boltdb-shipper-active

# Copier localement
kubectl cp loki-stack/loki-0:/tmp/loki-backup.tar.gz ./loki-backup-$(date +%Y%m%d).tar.gz

# Nettoyer
kubectl exec -n loki-stack loki-0 -- rm /tmp/loki-backup.tar.gz
```

**Restauration:**

```bash
# Copier backup dans pod
kubectl cp ./loki-backup-20251230.tar.gz loki-stack/loki-0:/tmp/

# ArrÃªter Loki
kubectl scale statefulset -n loki-stack loki --replicas=0

# Restaurer
kubectl exec -n loki-stack loki-0 -- tar xzf /tmp/loki-backup-20251230.tar.gz -C /

# RedÃ©marrer Loki
kubectl scale statefulset -n loki-stack loki --replicas=1
```

### 10.2 Backup MÃ©triques Prometheus

**StratÃ©gie:**

Prometheus stocke dans PVC `prometheus-kube-prometheus-prometheus-db`. Pour backup:

```bash
# Snapshot Prometheus (via API)
curl -X POST http://localhost:9090/api/v1/admin/tsdb/snapshot

# CrÃ©er backup du PVC
kubectl exec -n monitoring prometheus-prometheus-kube-prometheus-prometheus-0 \
  -- tar czf /tmp/prometheus-backup.tar.gz /prometheus

# Copier localement
kubectl cp monitoring/prometheus-prometheus-kube-prometheus-prometheus-0:/tmp/prometheus-backup.tar.gz \
  ./prometheus-backup-$(date +%Y%m%d).tar.gz
```

**Note:** Pour production, utiliser [Thanos](https://thanos.io/) ou [Cortex](https://cortexmetrics.io/) pour backup long-terme.

### 10.3 Mise Ã  Jour Observability Stack

```bash
# Mettre Ã  jour repos Helm
helm repo update

# VÃ©rifier nouvelles versions
helm search repo prometheus-community/kube-prometheus-stack
helm search repo grafana/loki
helm search repo grafana/promtail
helm search repo grafana/grafana

# Upgrade Prometheus Stack
helm upgrade prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/prometheus-values.yaml

# Upgrade Loki
helm upgrade loki grafana/loki \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/loki-modern-values.yaml

# Upgrade Promtail
helm upgrade promtail grafana/promtail \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/promtail-values.yaml

# Upgrade Grafana
helm upgrade grafana grafana/grafana \
  -n loki-stack \
  -f /home/leno-vo/git/repository/rhDemo/infra/stagingkub/helm/observability/grafana-values.yaml

# VÃ©rifier rollouts
kubectl rollout status statefulset -n monitoring prometheus-prometheus-kube-prometheus-prometheus
kubectl rollout status statefulset -n loki-stack loki
kubectl rollout status daemonset -n loki-stack promtail
kubectl rollout status deployment -n loki-stack grafana
```

### 10.4 Rotation des Logs et MÃ©triques (Automatique)

**Logs (Loki):**
- RÃ©tention: 7 jours (168h dÃ©fini dans `loki-modern-values.yaml`)
- Suppression automatique via `loki.limits_config.retention_period: 168h`
- Compaction automatique en mode SingleBinary

**MÃ©triques (Prometheus):**
- RÃ©tention: 7 jours (dÃ©fini dans `prometheus-values.yaml`)
- Taille max: 5GB (retentionSize)
- Suppression automatique par Prometheus TSDB

**VÃ©rifier compaction Loki:**

```bash
# Logs Loki (rechercher compaction)
kubectl logs -n loki-stack loki-0 | grep -i compactor
```

**VÃ©rifier TSDB Prometheus:**

```bash
# Status TSDB
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# AccÃ©der Ã  http://localhost:9090/tsdb-status
```

### 10.5 Monitoring de la Stack ObservabilitÃ©

**Si Prometheus dÃ©ployÃ©:**

Loki expose mÃ©triques sur `/metrics`:

```yaml
# ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: loki
  namespace: loki-stack
spec:
  selector:
    matchLabels:
      app: loki
  endpoints:
    - port: http-metrics
      interval: 30s
```

**MÃ©triques clÃ©s:**

| MÃ©trique | Description |
|----------|-------------|
| `loki_ingester_memory_chunks` | Chunks en mÃ©moire |
| `loki_ingester_received_bytes_total` | Bytes reÃ§us total |
| `loki_request_duration_seconds` | Latence requÃªtes |
| `loki_distributor_lines_received_total` | Lignes de logs reÃ§ues |

### 10.6 DÃ©sinstallation

**DÃ©sinstallation complÃ¨te de la stack ObservabilitÃ©:**

```bash
# DÃ©sinstaller Prometheus Stack
helm uninstall prometheus -n monitoring

# DÃ©sinstaller Loki Stack
helm uninstall loki -n loki-stack
helm uninstall promtail -n loki-stack
helm uninstall grafana -n loki-stack

# Supprimer PVCs (ATTENTION: perte de donnÃ©es)
kubectl delete pvc -n monitoring --all
kubectl delete pvc -n loki-stack --all

# Supprimer namespaces
kubectl delete namespace monitoring
kubectl delete namespace loki-stack

# Retirer du DNS
sudo sed -i '/grafana.stagingkub.local/d' /etc/hosts
```

**DÃ©sinstallation partielle (garder Loki, supprimer Prometheus):**

```bash
# DÃ©sinstaller uniquement Prometheus
helm uninstall prometheus -n monitoring
kubectl delete pvc -n monitoring --all
kubectl delete namespace monitoring

# Loki et Grafana restent fonctionnels (logs uniquement)
```

---

## 11. RESSOURCES UTILES

### Documentation Officielle

**Prometheus:**
- **Prometheus:** https://prometheus.io/docs/introduction/overview/
- **PromQL:** https://prometheus.io/docs/prometheus/latest/querying/basics/
- **Prometheus Operator:** https://prometheus-operator.dev/
- **kube-prometheus-stack:** https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack

**Loki:**
- **Loki:** https://grafana.com/docs/loki/latest/
- **Promtail:** https://grafana.com/docs/loki/latest/send-data/promtail/
- **LogQL:** https://grafana.com/docs/loki/latest/query/

**Grafana:**
- **Grafana:** https://grafana.com/docs/grafana/latest/
- **Dashboards:** https://grafana.com/grafana/dashboards/

**Helm Charts:**
- Prometheus Stack: https://github.com/prometheus-community/helm-charts
- Loki: https://github.com/grafana/helm-charts/tree/main/charts/loki
- Promtail: https://github.com/grafana/helm-charts/tree/main/charts/promtail
- Grafana: https://github.com/grafana/helm-charts/tree/main/charts/grafana

### Tutoriels

**Prometheus:**
- [Getting Started with Prometheus](https://prometheus.io/docs/prometheus/latest/getting_started/)
- [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)
- [Prometheus Best Practices](https://prometheus.io/docs/practices/)

**Loki:**
- [Getting Started with Loki](https://grafana.com/docs/loki/latest/getting-started/)
- [LogQL Cheat Sheet](https://megamorf.gitlab.io/cheat-sheets/loki/)
- [Grafana Loki Workshops](https://github.com/grafana/loki/tree/main/docs/workshops)

### CommunautÃ©

- **Prometheus GitHub:** https://github.com/prometheus/prometheus
- **Loki GitHub:** https://github.com/grafana/loki
- **Grafana Slack:** https://slack.grafana.com/
- **Grafana Forum:** https://community.grafana.com/
- **CNCF Slack:** https://slack.cncf.io/

### Documentation Projet rhDemo

- [GRAFANA_DASHBOARD.md](../infra/stagingkub/GRAFANA_DASHBOARD.md) - Documentation dashboard rhDemo Logs
- [POSTGRESQL_BACKUP_CRONJOBS.md](./POSTGRESQL_BACKUP_CRONJOBS.md) - Backups PostgreSQL automatiques


